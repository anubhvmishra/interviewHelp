{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7137a3fd",
   "metadata": {},
   "source": [
    "# Dynamic Question Suggestions\n",
    "Implementations for the core utilities:\n",
    "- `load_job_profile`\n",
    "- `load_resume_pdf`\n",
    "- `call_llm`\n",
    "- `suggest_questions`\n",
    "- `format_questions`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d28fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List\n",
    "import google.generativeai as genai\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "# Configure Google Gemini API key\n",
    "genai.configure(api_key=os.getenv('GOOGLE_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f614724d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_job_profile(filepath: str) -> str:\n",
    "    \"\"\"Read and return the content of a job profile text file.\"\"\"\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        return f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c714fa62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_resume_pdf(filepath: str) -> str:\n",
    "    \"\"\"Extract and return text content from a PDF resume.\"\"\"\n",
    "    reader = PdfReader(filepath)\n",
    "    text = ''\n",
    "    for page in reader.pages:\n",
    "        page_text = page.extract_text()\n",
    "        if page_text:\n",
    "            text += page_text + \"\\n\"\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cda58ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_llm(prompt: str) -> str:\n",
    "    \"\"\"Send a prompt to Google Gemini LLM and return its response.\"\"\"\n",
    "    #response = genai.ChatSession(\n",
    "    #    model=\"gemini-2.5-flash\",\n",
    "    #    prompt=prompt\n",
    "    #)\n",
    "    model = genai.GenerativeModel('gemini-2.5-flash')\n",
    "    chat = model.start_chat()\n",
    "    response = chat.send_message(prompt)\n",
    "    # response.text contains the generated content\n",
    "    return response.text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7268f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def suggest_questions(job_profile: str, resume_text: str) -> List[str]:\n",
    "    \"\"\"Generate question suggestions by combining job profile and resume context.\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "Based on the following job profile and resume, suggest five relevant interview questions.\n",
    "Also for every project mentioned in the resume, suggest two questions testing whether the individual has done the project by himself.\n",
    "\n",
    "Job Profile:\n",
    "{job_profile}\n",
    "\n",
    "Resume:\n",
    "{resume_text}\n",
    "\"\"\"\n",
    "    raw = call_llm(prompt)\n",
    "    # Split lines and clean bullets\n",
    "    questions = [line.strip('- ').strip() for line in raw.splitlines() if line.strip()]\n",
    "    return questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8dd10daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    job_profile_path = 'job_profile.txt'\n",
    "    resume_path = 'resume.pdf'\n",
    "\n",
    "    # Load job profile and resume\n",
    "    job_profile = load_job_profile(job_profile_path)\n",
    "    resume_text = load_resume_pdf(resume_path)\n",
    "\n",
    "    # Generate interview questions\n",
    "    questions = suggest_questions(job_profile, resume_text)\n",
    "\n",
    "    # Print the suggested questions\n",
    "    print(\"Suggested Interview Questions:\")\n",
    "    for i, question in enumerate(questions, start=1):\n",
    "        print(f\"{i}. {question}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5687265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested Interview Questions:\n",
      "1. Here are five relevant interview questions for Saurabh Gupta, followed by two verification questions for each project mentioned in his resume.\n",
      "2. \n",
      "3. ### Five Relevant Interview Questions:\n",
      "4. 1.  **Addressing Career Objectives & Alignment:**\n",
      "5. Your resume indicates a strong interest in pursuing graduate studies and a career in research, specifically in Computer Vision and Machine Learning. This role, however, is a Software Engineer position within Azure Core, focusing on cloud infrastructure and large-scale systems. Could you elaborate on what specifically attracts you to this particular software engineering role at Microsoft and how it aligns with your long-term career aspirations, despite your stated research interest?\n",
      "6. 2.  **Systems Thinking & Operational Excellence (Leveraging SysAdmin Role):**\n",
      "7. Your experience as a Department System Administrator, maintaining over 100 clients, 10 servers, and 15 IT services (like authentication, mailing, directory service), seems highly relevant to the operational and reliability aspects of this role, particularly the 'Designated Responsible Individual (DRI)' responsibilities. Can you describe a critical system degradation or outage you managed or helped resolve in that role? What was your process, what challenges did you face, and what steps did you take to prevent recurrence and improve the system's overall availability or efficiency?\n",
      "8. 3.  **Large-Scale System Design & Scalability:**\n",
      "9. The Azure Core team is responsible for creating foundational cloud infrastructure that scales to millions of users and devices. While your projects lean towards ML/CV, the \"Knowledge Management\" project involved designing and deploying IT services. Can you walk me through your thought process if you were tasked with designing a highly scalable, fault-tolerant service like the 'Project Database' you mentioned, for a global enterprise? What components would you consider, and how would you ensure its reliability and performance at scale?\n",
      "10. 4.  **Problem Solving & Engineering Trade-offs:**\n",
      "11. The role requires implementing features with \"good quality, high test coverage, security by design.\" Describe a challenging technical problem you encountered in one of your projects (e.g., during \"Improving Performance with MKL in SVMs\" or \"Funny Cell Assistant\") where you had to make significant engineering trade-offs (e.g., between performance and memory, or accuracy and speed, or security and usability). How did you analyze the trade-offs, make your decision, and what was the impact of your choice?\n",
      "12. 5.  **Proactive Learning & Adaptation to New Domains:**\n",
      "13. The Azure platform is a rapidly growing and evolving cloud environment. Given your strong academic background and project experience primarily in Computer Vision and Machine Learning, how do you approach learning completely new and complex technical domains like cloud infrastructure, distributed systems, and hardware provisioning? What steps would you take to quickly become proficient in Azure's internal services and contribute effectively to the team?\n",
      "14. \n",
      "15. ### Project Verification Questions:\n",
      "16. **Major Projects:**\n",
      "17. 1.  **Improving Performance with MKL in SVMs**\n",
      "18. *   **Q1:** You mentioned looking at \"new regularizers\" for the MKL objective. Can you describe one specific novel regularizer you investigated? What was its mathematical formulation, why did you believe it would improve performance or model complexity, and what were the empirical results *you* observed?\n",
      "19. *   **Q2:** Given that MKL often involves optimizing a complex objective function, what specific optimization algorithms or techniques did *you* implement or utilize? Were there any numerical stability or convergence issues you personally debugged, and how did you resolve them?\n",
      "20. 2.  **Unsupervised Video Surveillance**\n",
      "21. *   **Q1:** You used pLSA for clustering video clips. Can you explain your rationale for choosing pLSA over other unsupervised learning methods (e.g., K-Means, DBSCAN, or hierarchical clustering) for this particular task, especially considering the nature of video data and \"unusual activity\" detection?\n",
      "22. *   **Q2:** When extending the idea to \"multi-person unusual activity detection,\" what were the new challenges *you* encountered in defining or extracting features, or in adapting the pLSA model? Describe a specific modification or algorithm *you* introduced to handle the interactions or complexities of multiple subjects.\n",
      "23. **Other Projects:**\n",
      "24. 1.  **Captcha Reader**\n",
      "25. *   **Q1:** You mentioned \"letter segmentation.\" What specific image processing techniques did *you* apply to segment individual characters from the IITD webmail captcha image? Were there specific challenges due to noise, overlapping characters, or variations in fonts, and how did *you* address them in your code?\n",
      "26. *   **Q2:** You used a KNN classifier and trained it in a \"semi-supervised manner.\" Could you elaborate on *your specific approach* to semi-supervised learning in this context? How did you leverage the unlabeled captcha images to improve the classifier's accuracy, and what was the observed impact compared to a purely supervised approach?\n",
      "27. 2.  **Using Structural Information for Object Recognition**\n",
      "28. *   **Q1:** You \"investigated various feature vectors and techniques.\" Can you describe one specific technique *you* explored for incorporating structural information (e.g., spatial pyramids, constellation models, graph-based methods)? How did it represent the relationships between object parts, and what were its advantages and limitations based on your investigation?\n",
      "29. *   **Q2:** What were the primary datasets *you* used for your experiments, and how did *you* prepare or preprocess them? Did you implement any custom feature extraction pipelines, and if so, what were the challenges *you* faced in extracting these structural features from images?\n",
      "30. 3.  **Non Photo-realistic Rendering**\n",
      "31. *   **Q1:** You implemented \"color quantization\" and \"dithering.\" Could you describe the specific algorithms *you* chose for these steps (e.g., median cut, octree for quantization; Floyd-Steinberg, ordered dithering)? What were *your* criteria for selection, and how did *you* evaluate the visual quality of the output?\n",
      "32. *   **Q2:** For \"edge enhancement,\" you mentioned \"edge linking, differential thickening, and smoothing.\" Could you explain the purpose of each of these steps and the order in which *you* applied them? What specific algorithm did *you* use for \"edge linking,\" and what challenges did *you* face with disconnected or noisy edges?\n",
      "33. 4.  **Knowledge Management**\n",
      "34. *   **Q1:** This project involved customizing existing open-source Drupal and Foswiki projects by \"adding Kerberos authentication, LDAP integration.\" Could you walk me through the specific technical steps *you* undertook to integrate Kerberos and LDAP? What were the main configuration files, APIs, or code modifications *you* had to deal with, and what debugging steps *you* followed when issues arose?\n",
      "35. *   **Q2:** You \"designed intuitive user interfaces and work-flows\" and deployed these services. What was *your specific process* for gathering user requirements and feedback for these new web services? Can you describe one user interface or workflow improvement *you personally* designed for the \"Interest Group Discussion Forums\" or \"Campus Wiki\" and explain the user problem it aimed to solve?\n",
      "36. 5.  **Funny Cell Assistant**\n",
      "37. *   **Q1:** You \"designed and analyzed robust communication protocols\" for a \"molecule based inter-cell communication simulator\" in a \"loss-full unreliable medium.\" What were the primary sources of \"loss\" and \"unreliability\" in this simulated medium, and what specific mechanisms (e.g., redundancy, retransmission, error correction) did *you* incorporate into *your* protocol design to make it robust?\n",
      "38. *   **Q2:** When designing \"combat strategies against infection cells,\" what were the key parameters or behaviors *you* modeled for both the \"antibody cells\" and \"infection cells\"? Can you describe a specific strategy *you* devised for the antibody cells to counter the infection, and how did *you* evaluate its effectiveness within the simulator (e.g., metrics, simulation scenarios)?\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
